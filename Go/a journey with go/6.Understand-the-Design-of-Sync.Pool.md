![图片发布](https://miro.medium.com/max/5000/1*tVgnMO387vFxY46jRL3nZQ.png)

This️*本文基于 Go 1.12 和 1.13，并解释了这两个版本之间 sync / pool.go 的演变。*

该`sync`程序包提供了一个强大的实例池，这些实例池可以重复使用，以减轻垃圾收集器的压力。在使用该软件包之前，在使用该池之前和之后对应用程序进行基准测试非常重要，因为如果您不太了解它在内部的工作方式，则可能会降低性能。

# 游泳池的限制

让我们以一个基本示例为例，看看它如何在具有 1k 分配的非常简单的上下文中工作：

```go
type Small struct {
   a int
}

var pool = sync.Pool{
   New: func() interface{} { return new(Small) },
}

//go:noinline
func inc(s *Small) { s.a++ }

func BenchmarkWithoutPool(b *testing.B) {
   var s *Small
   for i := 0; i < b.N; i++ {
      for j := 0; j < 10000; j++ {
         s = &Small{ a: 1, }
         b.StopTimer(); inc(s); b.StartTimer()
      }
   }
}

func BenchmarkWithPool(b *testing.B) {
   var s *Small
   for i := 0; i < b.N; i++ {
      for j := 0; j < 10000; j++ {
         s = pool.Get().(*Small)
         s.a = 1
         b.StopTimer(); inc(s); b.StartTimer()
         pool.Put(s)
      }
   }
}
```

这是两个基准，一个基准不使用，`sync.Pool`另一个基准利用它：

```
name           time/op        alloc/op        allocs/op
WithoutPool-8  3.02ms ± 1%    160kB ± 0%      1.05kB ± 1%
WithPool-8     1.36ms ± 6%   1.05kB ± 0%        3.00 ± 0%
```

由于循环具有 10k 次迭代，因此不使用池的基准在堆上进行了 10k 分配，而使用池的基准仅进行了 3k 分配。这 3 个分配是由池进行的，但是仅分配了该结构的一个实例。到目前为止，一切都很好; 使用 sync.Pool 更快，消耗更少的内存。

但是，在现实世界中，当您使用池时，您的应用程序将对堆进行许多新分配。在这种情况下，当内存增加时，它将触发垃圾回收器。我们还可以使用以下命令强制垃圾收集器进入基准测试`runtime.GC()`：

```
name           time/op        alloc/op        allocs/op
WithoutPool-8  993ms ± 1%    249kB ± 2%      10.9k ± 0%
WithPool-8     1.03s ± 4%    10.6MB ± 0%     31.0k ± 0%
```

现在我们可以看到，随着池的使用，性能会降低，分配的数量和所使用的内存也会更高。让我们深入了解软件包以了解原因。

# 内部工作流程

深入研究`sync/pool.go`将向我们展示该软件包的初始化，它可以回答我们之前的关注：

```go
func init() {
   runtime_registerPoolCleanup(poolCleanup)
}
```

它作为清除池的方法注册到运行时。同样的方法将由垃圾收集器在其专用文件中触发`runtime/mgc.go`：

```go
func gcStart(trigger gcTrigger) {
   [...]
   // clearpools before we start the GC
   clearpools()
```

这就解释了为什么在调用垃圾收集器时性能会降低。每次垃圾收集器运行时都会清除池。[该文档也](https://golang.org/pkg/sync/#Pool)警告我们：

> 池中存储的任何项目都可以随时自动删除，恕不另行通知

现在，让我们创建工作流程以了解如何管理项目：

![图片发布](https://miro.medium.com/max/1144/1*OXMSVCef1UByrMBfK0_viQ.png)

Go 1.12 中的 sync.Pool 工作流程

对于`sync.Pool`我们创建的`poolLocal`每个处理器，go 都会生成一个附加到每个处理器的内部池。此内部池由两个属性组成：`private`和`shared`。第一个`shared`属性只能由其所有者访问（按入和弹出，因此不需要任何锁定），而其他任何处理器都可以读取该属性，并且该属性必须是并发安全的。实际上，该池不是一个简单的本地缓存，它有可能被我们应用程序中的任何线程/ goroutines 使用。

Go 的 1.13 版将改善对共享项的访问，还将带来一个新的缓存，该缓存应解决与垃圾收集器和清除池有关的问题。

# 新的无锁池和受害者缓存

Go 版本 1.13 引入了[一个新的双向链接列表](https://github.com/golang/go/commit/d5fd2dd6a17a816b7dfd99d4df70a85f1bf0de31#diff-491b0013c82345bf6cfa937bd78b690d)作为共享池，该[列表](https://github.com/golang/go/commit/d5fd2dd6a17a816b7dfd99d4df70a85f1bf0de31#diff-491b0013c82345bf6cfa937bd78b690d)消除了锁定并改善了共享访问。这是改善缓存的基础。这是共享访问的新工作流程：

![图片发布](https://miro.medium.com/max/1772/1*BAH0gDeO2OuF-m2qwvQVpA.png)

Go 1.13 中新的共享池

使用这个新的链接池，每个处理器在其队列的开头都具有推入式弹出功能，而共享访问将从尾部弹出。通过分配一个新的结构，该队列的头可以增加，该结构的两倍将由于`next`/`prev`属性而与前一个结构链接。初始结构的默认大小为 8 个项目。这意味着第二个结构将包含 16 个项目，第三个结构将包含 32 个项目，依此类推。
而且，现在不需要锁定，并且代码可以依赖于原子操作。

关于新缓存，新策略非常简单。现在有 2 组池：活动池和已归档池。运行垃圾收集器时，它将使每个池的引用保留在该池内的新属性，然后在清洗当前池之前将池的集合复制到已归档的池中：

```go
// Drop victim caches from all pools.
for _, p := range oldPools {
   p.victim = nil
   p.victimSize = 0
}

// Move primary cache to victim cache.
for _, p := range allPools {
   p.victim = p.local
   p.victimSize = p.localSize
   p.local = nil
   p.localSize = 0
}

// The pools with non-empty primary caches now have non-empty
// victim caches and no pools have primary caches.
oldPools, allPools = allPools, nil
```

通过这种策略，由于受害者缓存，该应用程序现在将有一个更多的垃圾收集器周期来创建/收集带有备份的新项目。在工作流中，将在共享池之后在过程结束时请求牺牲者缓存。
